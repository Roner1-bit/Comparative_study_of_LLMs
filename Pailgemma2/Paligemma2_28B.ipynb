{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elboardy/.local/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/elboardy/.local/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/elboardy/.local/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/elboardy/.local/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from transformers import PaliGemmaProcessor, PaliGemmaForConditionalGeneration\n",
    "from transformers.image_utils import load_image\n",
    "import torch\n",
    "import gc\n",
    "import traceback\n",
    "import numpy as np\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_dir = '/media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/'\n",
    "cache_dir = '/media/RLAB-Disk01/Large-Language-Models-Weights'\n",
    "model_id = \"google/paligemma2-28b-pt-896\"\n",
    "offload_folder = '/media/RLAB-Disk01/Large-Language-Models-Weights'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f8f4386e0a40c3bf235502e5013879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "processor = PaliGemmaProcessor.from_pretrained(model_id, \n",
    "                                               cache_dir=cache_dir,\n",
    "                                               #local_files_only=True\n",
    "                                               )\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        cache_dir=cache_dir,\n",
    "        attn_implementation=\"sdpa\",\n",
    "        offload_folder=offload_folder,\n",
    "        # local_files_only=True\n",
    "    ).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39 cases to process.\n"
     ]
    }
   ],
   "source": [
    "cases_to_process = []\n",
    "for case in os.listdir(cases_dir):\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    if os.path.isdir(case_dir):\n",
    "        response_path = os.path.join(case_dir, 'paligemma2-28b-report.txt')\n",
    "        if not os.path.exists(response_path):\n",
    "            cases_to_process.append(case)\n",
    "print(f\"Found {len(cases_to_process)} cases to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elboardy/anaconda3/envs/paligemma2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/elboardy/anaconda3/envs/paligemma2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RHUH-0001\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0001/RHUH-0001_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235279, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: T1\n",
      "Processing RHUH-0002\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0002/RHUH-0002_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0003\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0003/RHUH-0003_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235318,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     PFS: 0\n",
      "6\n",
      "Processing RHUH-0004\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0004/RHUH-0004_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235274, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     Post-operative chemotherapy: 10\n",
      "Processing RHUH-0005\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0005/RHUH-0005_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "T1\n",
      "T1c\n",
      "-\n",
      "Processing RHUH-0006\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0006/RHUH-0006_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235274, 235260,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     11c\n",
      "Processing RHUH-0007\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0007/RHUH-0007_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0008\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0008/RHUH-0008_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235321, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: 80\n",
      "Processing RHUH-0009\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0009/RHUH-0009_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,  13087, 235287,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: * Post-op T1* post contrast*\n",
      "Processing RHUH-0010\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0010/RHUH-0010_batch_5.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235274, 235260,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: 1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "T1c\n",
      "T1\n",
      "20\n",
      "4\n",
      "10\n",
      "1\n",
      "1\n",
      "T1c\n",
      "Processing RHUH-0011\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0011/RHUH-0011_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    141,    108,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: \n",
      "Processing RHUH-0012\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0012/RHUH-0012_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235279, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: T1\n",
      "20\n",
      "10\n",
      "0\n",
      "100\n",
      "G\n",
      "G\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "T1\n",
      "10\n",
      "C\n",
      "10\n",
      "10\n",
      "C\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "C\n",
      "C\n",
      "C\n",
      "10\n",
      "C\n",
      "T1\n",
      "T1\n",
      "C\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "T1\n",
      "10\n",
      "10\n",
      "10\n",
      "C\n",
      "T1\n",
      "T1\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "C\n",
      "T1\n",
      "10\n",
      "T1\n",
      "10\n",
      "T1\n",
      "C\n",
      "G\n",
      "C\n",
      "10\n",
      "10\n",
      "10\n",
      "T1\n",
      "Processing RHUH-0013\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0013/RHUH-0013_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235319, 115774,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: *\n",
      "1000*\n",
      "- *Glioma*\n",
      "Glioma\n",
      "Processing RHUH-0014\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0014/RHUH-0014_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235276, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: - 23.24\n",
      "- 23.24\n",
      "- 24.24\n",
      "- 100\n",
      "Processing RHUH-0015\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0015/RHUH-0015_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0016\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0016/RHUH-0016_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235274, 235260,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: T1\n",
      "T1c\n",
      "T1c\n",
      "Processing RHUH-0017\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0017/RHUH-0017_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0018\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0018/RHUH-0018_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235265, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: 73.0\n",
      "Processing RHUH-0020\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0020/RHUH-0020_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    141, 235319,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     G\n",
      "Processing RHUH-0021\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0021/RHUH-0021_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235279, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: T1\n",
      "Processing RHUH-0022\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0022/RHUH-0022_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0023\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0023/RHUH-0023_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0024\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0024/RHUH-0024_batch_5.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235287,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: *\n",
      "Processing RHUH-0025\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0025/RHUH-0025_batch_4.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,  44327,   1411,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     ##\n",
      "    Pituitary gland function\n",
      "14\n",
      "pituitary gland function\n",
      "Processing RHUH-0026\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0026/RHUH-0026_batch_5.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235321, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: 80\n",
      "Processing RHUH-0027\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0027/RHUH-0027_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235274, 235292,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: t1:\n",
      "Processing RHUH-0028\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0028/RHUH-0028_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235290,  29634,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: - Post-operative\n",
      "Processing RHUH-0029\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0029/RHUH-0029_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235279, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: T1\n",
      "Processing RHUH-0030\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0030/RHUH-0030_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     Post-contrast\n",
      "    Post-contrast +\n",
      "0\n",
      "Processing RHUH-0031\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0031/RHUH-0031_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235295, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     P1\n",
      "Processing RHUH-0032\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0032/RHUH-0032_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235274, 235260,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     T1\n",
      "T1c\n",
      "Processing RHUH-0033\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0033/RHUH-0033_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235279, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     Glioma - 100.0\n",
      "T1\n",
      "T1\n",
      "Processing RHUH-0034\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0034/RHUH-0034_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235279, 235274,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response:     T1\n",
      "Processing RHUH-0035\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0035/RHUH-0035_batch_7.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0036\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0036/RHUH-0036_batch_8.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235290,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: -\n",
      "Processing RHUH-0037\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0037/RHUH-0037_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235276, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: - Post-contrast\n",
      "- Post-contrast\n",
      "- 100\n",
      "- 100\n",
      "Processing RHUH-0038\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0038/RHUH-0038_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ..., 235265, 235276,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: T1\n",
      "103.0\n",
      "Processing RHUH-0039\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0039/RHUH-0039_batch_9.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    584, 235284,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: - T1\n",
      "- T2\n",
      "Processing RHUH-0040\n",
      "Loaded image: /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/RHUH-0040/RHUH-0040_batch_6.png\n",
      "Generated inputs\n",
      "Generated response\n",
      "tensor([[257152, 257152, 257152,  ...,    108, 235287,      1]],\n",
      "       device='cuda:0')\n",
      "Generated response: *\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def read_image_local(path):\n",
    "    # Open image from local path\n",
    "    image = PIL.Image.open(path)\n",
    "    # Convert to numpy array\n",
    "    image = np.array(image)\n",
    "    # Remove alpha channel if necessary\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "failed_cases = []\n",
    "    \n",
    "for case in cases_to_process:\n",
    "        case_dir = os.path.join(cases_dir, case)\n",
    "        try:\n",
    "            # Load clinical info\n",
    "            clinical_path = os.path.join(case_dir, 'diagnostic_prompt.txt')\n",
    "            if not os.path.exists(clinical_path):\n",
    "                print(f\"Missing clinical info for {case}\")\n",
    "                failed_cases.append(case)\n",
    "                continue\n",
    "                \n",
    "            clinical_info = open(clinical_path).read()\n",
    "\n",
    "            # Build prompts\n",
    "            system_prompt = \"\"\"<image> \\nConsider that you are a professional radiologist with several years of experience and you are now treating a patient. Write a fully detailed diagnosis report for this case, avoiding any potential hallucination and paying close attention to all of the batch images attached to this message.\n",
    "\n",
    "Use the following structure for the report:\n",
    "\n",
    "## Radiologist's Report\n",
    "\n",
    "### Patient Information:\n",
    "- *Age:* 65\n",
    "- *Sex:* Male\n",
    "- *Days from earliest imaging to surgery:* 1\n",
    "- *Histopathological Subtype:* Glioblastoma\n",
    "- *WHO Grade:* 4\n",
    "- *IDH Status:* Mutant\n",
    "- *Preoperative KPS:* 80\n",
    "- *Preoperative Contrast-Enhancing Tumor Volume (cm³):* 103.21\n",
    "- *Preoperative T2/FLAIR Abnormality (cm³):* 36.29\n",
    "- *Extent of Resection (EOR %):* 100.0\n",
    "- *EOR Type:* Gross Total Resection (GTR)\n",
    "- *Adjuvant Therapy:* Radiotherapy (RT) + Temozolomide (TMZ)\n",
    "- *Progression-Free Survival (PFS) Days:* 649\n",
    "- *Overall Survival (OS) Days:* 736\n",
    "\n",
    "#### Tumor Characteristics:\n",
    "\n",
    "#### Segmentation Analysis:\n",
    "\n",
    "#### Surgical Considerations:\n",
    "\n",
    "### Clinical Summary:\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "### Prognostic Considerations:\n",
    "\n",
    "### Follow-Up Plan:\n",
    "\n",
    "### Additional Notes*(if any)*:\n",
    "\n",
    "Ensure all findings from all of the images and clinical data provided. Please mention at the end of the report how many images were reviewed.\"\"\"\n",
    "\n",
    "            user_prompt = f\"\"\"You will be given batches of images, which are different sequences of MRI scans. \n",
    "    The images are for patients who are likely to have a brain tumor. Each image will contain up to 10 slices for 5 different sequences and the segmentation masks for the tumor at the bottom row of the image. \n",
    "    Additional clinical data about the patient is: \n",
    "    {clinical_info}\"\"\"\n",
    "\n",
    "\n",
    "            full_prompt = system_prompt + \"\\n\\n\" + user_prompt\n",
    "\n",
    "            print(f\"Processing {case}\")\n",
    "            # Load image\n",
    "            image_files = [f for f in os.listdir(case_dir) if f.lower().endswith('.png')]\n",
    "            if not image_files:\n",
    "                print(f\"No images found for {case}\")\n",
    "                failed_cases.append(case)\n",
    "                continue\n",
    "                \n",
    "            image_path = os.path.join(case_dir, image_files[-1])  # Using last image\n",
    "            image = read_image_local(image_path)\n",
    "            print(f\"Loaded image: {image_path}\")\n",
    "        \n",
    "            # Process inputs\n",
    "            model_inputs = processor(\n",
    "                text=full_prompt,\n",
    "                images=image,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "\n",
    "            model_inputs = model_inputs.to(dtype=model.dtype)\n",
    "            input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "            print(\"Generated inputs\")\n",
    "            # Generate response\n",
    "            with torch.inference_mode():\n",
    "                generation = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=4096,\n",
    "                    do_sample=False,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9,\n",
    "                )\n",
    "            print(\"Generated response\")\n",
    "            print(generation)    \n",
    "            generation = generation[0][input_len:]\n",
    "            response = processor.decode(generation, skip_special_tokens=True)\n",
    "            print(f\"Generated response: {response}\")\n",
    "            # Save response\n",
    "            with open(os.path.join(case_dir, 'paligemma2-28b-report.txt'), 'w', encoding='utf-8') as f:\n",
    "                f.write(response.strip())\n",
    "\n",
    "            # Cleanup\n",
    "            del model_inputs, generation, response\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"\\nError processing {case}:\\n{traceback.format_exc()}\"\n",
    "            print(error_msg)\n",
    "            failed_cases.append(case)\n",
    "\n",
    "    # Save failed cases\n",
    "if failed_cases:\n",
    "        with open(os.path.join(cases_dir, 'failed_paligemma2-28b.txt'), 'w') as f:\n",
    "            f.write(\"\\n\".join(failed_cases))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paligemma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
