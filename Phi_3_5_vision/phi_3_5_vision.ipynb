{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-3.5-vision-instruct\"\n",
    "cases_dir = '/media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized'\n",
    "cache_dir = '/media/RLAB-Disk01/Large-Language-Models-Weights'\n",
    "offload_folder = '/media/RLAB-Disk01/Large-Language-Models-Weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
    "#torch.cuda.set_per_process_memory_fraction(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Make sure cases_dir is properly defined\n",
    "# # cases_dir = \"your/cases/directory/path\"\n",
    "\n",
    "# deleted_count = 0\n",
    "# for case in os.listdir(cases_dir):\n",
    "#     case_dir = os.path.join(cases_dir, case)\n",
    "#     if os.path.isdir(case_dir):\n",
    "#         response_path = os.path.join(case_dir, 'phi-3.5-vision-instruct-response.txt')\n",
    "#         if os.path.exists(response_path):\n",
    "#             try:\n",
    "#                 os.remove(response_path)\n",
    "#                 deleted_count += 1\n",
    "#                 print(f\"Deleted: {response_path}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error deleting {response_path}: {str(e)}\")\n",
    "\n",
    "# print(f\"\\nDeleted {deleted_count} response files.\")\n",
    "# print(f\"Remaining cases without response file: {len(os.listdir(cases_dir)) - deleted_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 cases to process.\n"
     ]
    }
   ],
   "source": [
    "cases_to_process = []\n",
    "for case in os.listdir(cases_dir):\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    if os.path.isdir(case_dir):\n",
    "        response_path = os.path.join(case_dir, 'phi-3.5-vision-instruct-response.txt')\n",
    "        if not os.path.exists(response_path):\n",
    "            cases_to_process.append(case)\n",
    "print(f\"Found {len(cases_to_process)} cases to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation='flash_attention_2',\n",
    "    cache_dir=cache_dir,\n",
    "    offload_folder=offload_folder\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    num_crops=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing case: RHUH-0019\n",
      "Completed case RHUH-0019\n",
      "\n",
      "Processing case: RHUH-0001\n",
      "Completed case RHUH-0001\n",
      "\n",
      "Processing case: RHUH-0002\n",
      "Completed case RHUH-0002\n",
      "\n",
      "Processing case: RHUH-0003\n",
      "Completed case RHUH-0003\n",
      "\n",
      "Processing case: RHUH-0004\n",
      "Completed case RHUH-0004\n",
      "\n",
      "Processing case: RHUH-0005\n",
      "Completed case RHUH-0005\n",
      "\n",
      "Processing case: RHUH-0006\n",
      "Completed case RHUH-0006\n",
      "\n",
      "Processing case: RHUH-0007\n",
      "Completed case RHUH-0007\n",
      "\n",
      "Processing case: RHUH-0008\n",
      "Completed case RHUH-0008\n",
      "\n",
      "Processing case: RHUH-0009\n",
      "Completed case RHUH-0009\n",
      "\n",
      "Processing case: RHUH-0010\n",
      "Completed case RHUH-0010\n",
      "\n",
      "Processing case: RHUH-0011\n",
      "Completed case RHUH-0011\n",
      "\n",
      "Processing case: RHUH-0012\n",
      "Completed case RHUH-0012\n",
      "\n",
      "Processing case: RHUH-0013\n",
      "Completed case RHUH-0013\n",
      "\n",
      "Processing case: RHUH-0014\n",
      "Completed case RHUH-0014\n",
      "\n",
      "Processing case: RHUH-0015\n",
      "Completed case RHUH-0015\n",
      "\n",
      "Processing case: RHUH-0016\n",
      "Completed case RHUH-0016\n",
      "\n",
      "Processing case: RHUH-0017\n",
      "Completed case RHUH-0017\n",
      "\n",
      "Processing case: RHUH-0018\n",
      "Completed case RHUH-0018\n",
      "\n",
      "Processing case: RHUH-0020\n",
      "Completed case RHUH-0020\n",
      "\n",
      "Processing case: RHUH-0021\n",
      "Completed case RHUH-0021\n",
      "\n",
      "Processing case: RHUH-0022\n",
      "Completed case RHUH-0022\n",
      "\n",
      "Processing case: RHUH-0023\n",
      "Completed case RHUH-0023\n",
      "\n",
      "Processing case: RHUH-0024\n",
      "Completed case RHUH-0024\n",
      "\n",
      "Processing case: RHUH-0025\n",
      "Completed case RHUH-0025\n",
      "\n",
      "Processing case: RHUH-0026\n",
      "Completed case RHUH-0026\n",
      "\n",
      "Processing case: RHUH-0027\n",
      "Completed case RHUH-0027\n",
      "\n",
      "Processing case: RHUH-0028\n",
      "Completed case RHUH-0028\n",
      "\n",
      "Processing case: RHUH-0029\n",
      "Completed case RHUH-0029\n",
      "\n",
      "Processing case: RHUH-0030\n",
      "Completed case RHUH-0030\n",
      "\n",
      "Processing case: RHUH-0031\n",
      "Completed case RHUH-0031\n",
      "\n",
      "Processing case: RHUH-0032\n",
      "Completed case RHUH-0032\n",
      "\n",
      "Processing case: RHUH-0033\n",
      "Completed case RHUH-0033\n",
      "\n",
      "Processing case: RHUH-0034\n",
      "Completed case RHUH-0034\n",
      "\n",
      "Processing case: RHUH-0035\n",
      "Completed case RHUH-0035\n",
      "\n",
      "Processing case: RHUH-0036\n",
      "Completed case RHUH-0036\n",
      "\n",
      "Processing case: RHUH-0037\n",
      "Completed case RHUH-0037\n",
      "\n",
      "Processing case: RHUH-0038\n",
      "Completed case RHUH-0038\n",
      "\n",
      "Processing case: RHUH-0039\n",
      "Completed case RHUH-0039\n",
      "\n",
      "Processing case: RHUH-0040\n",
      "Completed case RHUH-0040\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "failed_cases = []\n",
    "\n",
    "for case in cases_to_process:\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    print(f\"\\nProcessing case: {case}\")\n",
    "    image_files = [\n",
    "        f for f in os.listdir(case_dir)\n",
    "        if f.lower().endswith('.png')\n",
    "    ]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Load clinical information\n",
    "        clinical_info_path = os.path.join(case_dir, 'diagnostic_prompt.txt')\n",
    "        if not os.path.exists(clinical_info_path):\n",
    "            raise FileNotFoundError(f\"Missing clinical info: {clinical_info_path}\")\n",
    "            \n",
    "        with open(clinical_info_path, 'r', encoding='utf-8') as f:\n",
    "            clinical_info = f.read()\n",
    "\n",
    "        # Prepare prompts\n",
    "        system_prompt = \"\"\"Consider that you are a professional radiologist with several years of experience and you are now treating a patient. Write a fully detailed diagnosis report for this case, avoiding any potential hallucination and paying close attention to all of the batch images attached to this message.\n",
    "\n",
    "Use the following structure for the report:\n",
    "\n",
    "## Radiologist's Report\n",
    "\n",
    "### Patient Information:\n",
    "- *Age:* 65\n",
    "- *Sex:* Male\n",
    "- *Days from earliest imaging to surgery:* 1\n",
    "- *Histopathological Subtype:* Glioblastoma\n",
    "- *WHO Grade:* 4\n",
    "- *IDH Status:* Mutant\n",
    "- *Preoperative KPS:* 80\n",
    "- *Preoperative Contrast-Enhancing Tumor Volume (cm³):* 103.21\n",
    "- *Preoperative T2/FLAIR Abnormality (cm³):* 36.29\n",
    "- *Extent of Resection (EOR %):* 100.0\n",
    "- *EOR Type:* Gross Total Resection (GTR)\n",
    "- *Adjuvant Therapy:* Radiotherapy (RT) + Temozolomide (TMZ)\n",
    "- *Progression-Free Survival (PFS) Days:* 649\n",
    "- *Overall Survival (OS) Days:* 736\n",
    "\n",
    "#### Tumor Characteristics:\n",
    "\n",
    "#### Segmentation Analysis:\n",
    "\n",
    "#### Surgical Considerations:\n",
    "\n",
    "### Clinical Summary:\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "### Prognostic Considerations:\n",
    "\n",
    "### Follow-Up Plan:\n",
    "\n",
    "### Additional Notes*(if any)*:\n",
    "\n",
    "Ensure all findings from all of the images and clinical data provided. Please mention at the end of the report how many images were reviewed.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"You will be given batches of images, which are different sequences of MRI scans. \n",
    "        The images are for patients who are likely to have a brain tumor. Each image will contain up to 10 slices for 5 different sequences and the segmentation masks for the tumor at the bottom row of the image. \n",
    "        Additional clinical data about the patient is: \n",
    "        {clinical_info}.\"\"\"\n",
    "        # Create image placeholders\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(case_dir, image_file)\n",
    "            img = load_image(image_path)\n",
    "   \n",
    "        images=[]\n",
    "        images.append(img)\n",
    "        \n",
    "        image_placeholders = \"\\n\".join([f\"<|image_{i+1}|>\" for i in range(len(images))])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"{image_placeholders}\\n{user_prompt}\"},\n",
    "        ]\n",
    "\n",
    "        # messages = [\n",
    "        #     {\"role\": \"user\", \"content\": f\"{image_placeholders}\\n{system_prompt}\\n{user_prompt}\"},\n",
    "        # ]\n",
    "\n",
    "        # Process inputs\n",
    "        prompt = processor.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        inputs = processor(\n",
    "            text=prompt,\n",
    "            images=images,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        # Generate response\n",
    "        generation_args = {\n",
    "            \"max_new_tokens\": 4096,\n",
    "            \"temperature\": 0.7,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "        \n",
    "        generate_ids = model.generate(\n",
    "            **inputs,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            **generation_args\n",
    "        )\n",
    "\n",
    "        # Decode response\n",
    "        response = processor.batch_decode(\n",
    "            generate_ids[:, inputs['input_ids'].shape[1]:],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "\n",
    "        # Save results\n",
    "        with open(os.path.join(case_dir, 'phi-3.5-vision-instruct-response.txt'), \n",
    "                 'w', encoding='utf-8') as f:\n",
    "            f.write(response)\n",
    "\n",
    "        # Cleanup\n",
    "        del inputs, generate_ids, response\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Completed case {case}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case}: {str(e)}\")\n",
    "        failed_cases.append(case)\n",
    "        continue\n",
    "\n",
    "# Save failed cases log\n",
    "if failed_cases:\n",
    "    with open(os.path.join(cases_dir, 'phi3_failed_cases.txt'), 'w') as f:\n",
    "        f.write(\"\\n\".join(failed_cases))\n",
    "    print(f\"Logged {len(failed_cases)} failed cases\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi_3_5_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
