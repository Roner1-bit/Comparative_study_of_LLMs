{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Define paths and model configuration\n",
    "model_id = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "cases_dir = '/media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/'\n",
    "cache_dir = '/media/RLAB-Disk01/Large-Language-Models-Weights'\n",
    "offload_folder = '/media/RLAB-Disk01/Large-Language-Models-Weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
    "# torch.cuda.set_per_process_memory_fraction(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 cases to process.\n"
     ]
    }
   ],
   "source": [
    "# Collect list of cases that do not have 'qwen-vl-72b-response.txt'\n",
    "cases_to_process = []\n",
    "for case in os.listdir(cases_dir):\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    if os.path.isdir(case_dir):\n",
    "        response_path = os.path.join(case_dir, 'qwen-vl-2b-response.txt')\n",
    "        if not os.path.exists(response_path):\n",
    "            cases_to_process.append(case)\n",
    "print(f\"Found {len(cases_to_process)} cases to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oSMBJLK1t3hX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and processor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3116375c690c4532ab3ba2ba56114856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model and processor\n",
    "print(\"Loading model and processor...\")\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir,\n",
    "    offload_folder=offload_folder,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "print(\"Model and processor loaded successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cases...--->\n",
      "['RHUH-0019', 'RHUH-0001', 'RHUH-0002', 'RHUH-0003', 'RHUH-0004', 'RHUH-0005', 'RHUH-0006', 'RHUH-0007', 'RHUH-0008', 'RHUH-0009', 'RHUH-0010', 'RHUH-0011', 'RHUH-0012', 'RHUH-0013', 'RHUH-0014', 'RHUH-0015', 'RHUH-0016', 'RHUH-0017', 'RHUH-0018', 'RHUH-0020', 'RHUH-0021', 'RHUH-0022', 'RHUH-0023', 'RHUH-0024', 'RHUH-0025', 'RHUH-0026', 'RHUH-0027', 'RHUH-0028', 'RHUH-0029', 'RHUH-0030', 'RHUH-0031', 'RHUH-0032', 'RHUH-0033', 'RHUH-0034', 'RHUH-0035', 'RHUH-0036', 'RHUH-0037', 'RHUH-0038', 'RHUH-0039', 'RHUH-0040']\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing cases...--->\")\n",
    "print(cases_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 image files for case RHUH-0019\n",
      "Reading clinical information for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_1.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_2.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_3.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_4.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_5.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_6.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_7.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_8.png for case RHUH-0019\n",
      "Loaded image: RHUH-0019_batch_9.png for case RHUH-0019\n",
      "Messages prepared for case RHUH-0019\n",
      "Processing inputs for case RHUH-0019\n",
      "Response generated for case RHUH-0019, length: 2984 characters\n",
      "Response saved for case RHUH-0019.\n",
      "Memory cleared for case RHUH-0019\n",
      "Found 6 image files for case RHUH-0001\n",
      "Reading clinical information for case RHUH-0001\n",
      "Loaded image: RHUH-0001_batch_1.png for case RHUH-0001\n",
      "Loaded image: RHUH-0001_batch_2.png for case RHUH-0001\n",
      "Loaded image: RHUH-0001_batch_3.png for case RHUH-0001\n",
      "Loaded image: RHUH-0001_batch_4.png for case RHUH-0001\n",
      "Loaded image: RHUH-0001_batch_5.png for case RHUH-0001\n",
      "Loaded image: RHUH-0001_batch_6.png for case RHUH-0001\n",
      "Messages prepared for case RHUH-0001\n",
      "Processing inputs for case RHUH-0001\n",
      "Response generated for case RHUH-0001, length: 3180 characters\n",
      "Response saved for case RHUH-0001.\n",
      "Memory cleared for case RHUH-0001\n",
      "Found 6 image files for case RHUH-0002\n",
      "Reading clinical information for case RHUH-0002\n",
      "Loaded image: RHUH-0002_batch_1.png for case RHUH-0002\n",
      "Loaded image: RHUH-0002_batch_2.png for case RHUH-0002\n",
      "Loaded image: RHUH-0002_batch_3.png for case RHUH-0002\n",
      "Loaded image: RHUH-0002_batch_4.png for case RHUH-0002\n",
      "Loaded image: RHUH-0002_batch_5.png for case RHUH-0002\n",
      "Loaded image: RHUH-0002_batch_6.png for case RHUH-0002\n",
      "Messages prepared for case RHUH-0002\n",
      "Processing inputs for case RHUH-0002\n",
      "Response generated for case RHUH-0002, length: 45009 characters\n",
      "Response saved for case RHUH-0002.\n",
      "Memory cleared for case RHUH-0002\n",
      "Found 6 image files for case RHUH-0003\n",
      "Reading clinical information for case RHUH-0003\n",
      "Loaded image: RHUH-0003_batch_1.png for case RHUH-0003\n",
      "Loaded image: RHUH-0003_batch_2.png for case RHUH-0003\n",
      "Loaded image: RHUH-0003_batch_3.png for case RHUH-0003\n",
      "Loaded image: RHUH-0003_batch_4.png for case RHUH-0003\n",
      "Loaded image: RHUH-0003_batch_5.png for case RHUH-0003\n",
      "Loaded image: RHUH-0003_batch_6.png for case RHUH-0003\n",
      "Messages prepared for case RHUH-0003\n",
      "Processing inputs for case RHUH-0003\n",
      "Response generated for case RHUH-0003, length: 3621 characters\n",
      "Response saved for case RHUH-0003.\n",
      "Memory cleared for case RHUH-0003\n",
      "Found 7 image files for case RHUH-0004\n",
      "Reading clinical information for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_1.png for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_2.png for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_3.png for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_4.png for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_5.png for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_6.png for case RHUH-0004\n",
      "Loaded image: RHUH-0004_batch_7.png for case RHUH-0004\n",
      "Messages prepared for case RHUH-0004\n",
      "Processing inputs for case RHUH-0004\n",
      "Response generated for case RHUH-0004, length: 12512 characters\n",
      "Response saved for case RHUH-0004.\n",
      "Memory cleared for case RHUH-0004\n",
      "Found 6 image files for case RHUH-0005\n",
      "Reading clinical information for case RHUH-0005\n",
      "Loaded image: RHUH-0005_batch_1.png for case RHUH-0005\n",
      "Loaded image: RHUH-0005_batch_2.png for case RHUH-0005\n",
      "Loaded image: RHUH-0005_batch_3.png for case RHUH-0005\n",
      "Loaded image: RHUH-0005_batch_4.png for case RHUH-0005\n",
      "Loaded image: RHUH-0005_batch_5.png for case RHUH-0005\n",
      "Loaded image: RHUH-0005_batch_6.png for case RHUH-0005\n",
      "Messages prepared for case RHUH-0005\n",
      "Processing inputs for case RHUH-0005\n",
      "Response generated for case RHUH-0005, length: 12749 characters\n",
      "Response saved for case RHUH-0005.\n",
      "Memory cleared for case RHUH-0005\n",
      "Found 8 image files for case RHUH-0006\n",
      "Reading clinical information for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_1.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_2.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_3.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_4.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_5.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_6.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_7.png for case RHUH-0006\n",
      "Loaded image: RHUH-0006_batch_8.png for case RHUH-0006\n",
      "Messages prepared for case RHUH-0006\n",
      "Processing inputs for case RHUH-0006\n",
      "Response generated for case RHUH-0006, length: 3750 characters\n",
      "Response saved for case RHUH-0006.\n",
      "Memory cleared for case RHUH-0006\n",
      "Found 7 image files for case RHUH-0007\n",
      "Reading clinical information for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_1.png for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_2.png for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_3.png for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_4.png for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_5.png for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_6.png for case RHUH-0007\n",
      "Loaded image: RHUH-0007_batch_7.png for case RHUH-0007\n",
      "Messages prepared for case RHUH-0007\n",
      "Processing inputs for case RHUH-0007\n",
      "Response generated for case RHUH-0007, length: 11597 characters\n",
      "Response saved for case RHUH-0007.\n",
      "Memory cleared for case RHUH-0007\n",
      "Found 7 image files for case RHUH-0008\n",
      "Reading clinical information for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_1.png for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_2.png for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_3.png for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_4.png for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_5.png for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_6.png for case RHUH-0008\n",
      "Loaded image: RHUH-0008_batch_7.png for case RHUH-0008\n",
      "Messages prepared for case RHUH-0008\n",
      "Processing inputs for case RHUH-0008\n",
      "Response generated for case RHUH-0008, length: 2612 characters\n",
      "Response saved for case RHUH-0008.\n",
      "Memory cleared for case RHUH-0008\n",
      "Found 8 image files for case RHUH-0009\n",
      "Reading clinical information for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_1.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_2.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_3.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_4.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_5.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_6.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_7.png for case RHUH-0009\n",
      "Loaded image: RHUH-0009_batch_8.png for case RHUH-0009\n",
      "Messages prepared for case RHUH-0009\n",
      "Processing inputs for case RHUH-0009\n",
      "Response generated for case RHUH-0009, length: 2343 characters\n",
      "Response saved for case RHUH-0009.\n",
      "Memory cleared for case RHUH-0009\n",
      "Found 5 image files for case RHUH-0010\n",
      "Reading clinical information for case RHUH-0010\n",
      "Loaded image: RHUH-0010_batch_1.png for case RHUH-0010\n",
      "Loaded image: RHUH-0010_batch_2.png for case RHUH-0010\n",
      "Loaded image: RHUH-0010_batch_3.png for case RHUH-0010\n",
      "Loaded image: RHUH-0010_batch_4.png for case RHUH-0010\n",
      "Loaded image: RHUH-0010_batch_5.png for case RHUH-0010\n",
      "Messages prepared for case RHUH-0010\n",
      "Processing inputs for case RHUH-0010\n",
      "Response generated for case RHUH-0010, length: 10263 characters\n",
      "Response saved for case RHUH-0010.\n",
      "Memory cleared for case RHUH-0010\n",
      "Found 7 image files for case RHUH-0011\n",
      "Reading clinical information for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_1.png for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_2.png for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_3.png for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_4.png for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_5.png for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_6.png for case RHUH-0011\n",
      "Loaded image: RHUH-0011_batch_7.png for case RHUH-0011\n",
      "Messages prepared for case RHUH-0011\n",
      "Processing inputs for case RHUH-0011\n",
      "Response generated for case RHUH-0011, length: 2571 characters\n",
      "Response saved for case RHUH-0011.\n",
      "Memory cleared for case RHUH-0011\n",
      "Found 9 image files for case RHUH-0012\n",
      "Reading clinical information for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_1.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_2.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_3.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_4.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_5.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_6.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_7.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_8.png for case RHUH-0012\n",
      "Loaded image: RHUH-0012_batch_9.png for case RHUH-0012\n",
      "Messages prepared for case RHUH-0012\n",
      "Processing inputs for case RHUH-0012\n",
      "Response generated for case RHUH-0012, length: 13413 characters\n",
      "Response saved for case RHUH-0012.\n",
      "Memory cleared for case RHUH-0012\n",
      "Found 9 image files for case RHUH-0013\n",
      "Reading clinical information for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_1.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_2.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_3.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_4.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_5.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_6.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_7.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_8.png for case RHUH-0013\n",
      "Loaded image: RHUH-0013_batch_9.png for case RHUH-0013\n",
      "Messages prepared for case RHUH-0013\n",
      "Processing inputs for case RHUH-0013\n",
      "Response generated for case RHUH-0013, length: 3222 characters\n",
      "Response saved for case RHUH-0013.\n",
      "Memory cleared for case RHUH-0013\n",
      "Found 11 image files for case RHUH-0014\n",
      "Reading clinical information for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_1.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_10.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_11.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_2.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_3.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_4.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_5.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_6.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_7.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_8.png for case RHUH-0014\n",
      "Loaded image: RHUH-0014_batch_9.png for case RHUH-0014\n",
      "Messages prepared for case RHUH-0014\n",
      "Processing inputs for case RHUH-0014\n",
      "Response generated for case RHUH-0014, length: 2665 characters\n",
      "Response saved for case RHUH-0014.\n",
      "Memory cleared for case RHUH-0014\n",
      "Found 6 image files for case RHUH-0015\n",
      "Reading clinical information for case RHUH-0015\n",
      "Loaded image: RHUH-0015_batch_1.png for case RHUH-0015\n",
      "Loaded image: RHUH-0015_batch_2.png for case RHUH-0015\n",
      "Loaded image: RHUH-0015_batch_3.png for case RHUH-0015\n",
      "Loaded image: RHUH-0015_batch_4.png for case RHUH-0015\n",
      "Loaded image: RHUH-0015_batch_5.png for case RHUH-0015\n",
      "Loaded image: RHUH-0015_batch_6.png for case RHUH-0015\n",
      "Messages prepared for case RHUH-0015\n",
      "Processing inputs for case RHUH-0015\n",
      "Response generated for case RHUH-0015, length: 12001 characters\n",
      "Response saved for case RHUH-0015.\n",
      "Memory cleared for case RHUH-0015\n",
      "Found 7 image files for case RHUH-0016\n",
      "Reading clinical information for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_1.png for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_2.png for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_3.png for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_4.png for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_5.png for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_6.png for case RHUH-0016\n",
      "Loaded image: RHUH-0016_batch_7.png for case RHUH-0016\n",
      "Messages prepared for case RHUH-0016\n",
      "Processing inputs for case RHUH-0016\n",
      "Response generated for case RHUH-0016, length: 2873 characters\n",
      "Response saved for case RHUH-0016.\n",
      "Memory cleared for case RHUH-0016\n",
      "Found 6 image files for case RHUH-0017\n",
      "Reading clinical information for case RHUH-0017\n",
      "Loaded image: RHUH-0017_batch_1.png for case RHUH-0017\n",
      "Loaded image: RHUH-0017_batch_2.png for case RHUH-0017\n",
      "Loaded image: RHUH-0017_batch_3.png for case RHUH-0017\n",
      "Loaded image: RHUH-0017_batch_4.png for case RHUH-0017\n",
      "Loaded image: RHUH-0017_batch_5.png for case RHUH-0017\n",
      "Loaded image: RHUH-0017_batch_6.png for case RHUH-0017\n",
      "Messages prepared for case RHUH-0017\n",
      "Processing inputs for case RHUH-0017\n",
      "Response generated for case RHUH-0017, length: 3293 characters\n",
      "Response saved for case RHUH-0017.\n",
      "Memory cleared for case RHUH-0017\n",
      "Found 8 image files for case RHUH-0018\n",
      "Reading clinical information for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_1.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_2.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_3.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_4.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_5.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_6.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_7.png for case RHUH-0018\n",
      "Loaded image: RHUH-0018_batch_8.png for case RHUH-0018\n",
      "Messages prepared for case RHUH-0018\n",
      "Processing inputs for case RHUH-0018\n",
      "Response generated for case RHUH-0018, length: 12212 characters\n",
      "Response saved for case RHUH-0018.\n",
      "Memory cleared for case RHUH-0018\n",
      "Found 8 image files for case RHUH-0020\n",
      "Reading clinical information for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_1.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_2.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_3.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_4.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_5.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_6.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_7.png for case RHUH-0020\n",
      "Loaded image: RHUH-0020_batch_8.png for case RHUH-0020\n",
      "Messages prepared for case RHUH-0020\n",
      "Processing inputs for case RHUH-0020\n",
      "Response generated for case RHUH-0020, length: 2952 characters\n",
      "Response saved for case RHUH-0020.\n",
      "Memory cleared for case RHUH-0020\n",
      "Found 6 image files for case RHUH-0021\n",
      "Reading clinical information for case RHUH-0021\n",
      "Loaded image: RHUH-0021_batch_1.png for case RHUH-0021\n",
      "Loaded image: RHUH-0021_batch_2.png for case RHUH-0021\n",
      "Loaded image: RHUH-0021_batch_3.png for case RHUH-0021\n",
      "Loaded image: RHUH-0021_batch_4.png for case RHUH-0021\n",
      "Loaded image: RHUH-0021_batch_5.png for case RHUH-0021\n",
      "Loaded image: RHUH-0021_batch_6.png for case RHUH-0021\n",
      "Messages prepared for case RHUH-0021\n",
      "Processing inputs for case RHUH-0021\n",
      "Response generated for case RHUH-0021, length: 2612 characters\n",
      "Response saved for case RHUH-0021.\n",
      "Memory cleared for case RHUH-0021\n",
      "Found 7 image files for case RHUH-0022\n",
      "Reading clinical information for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_1.png for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_2.png for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_3.png for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_4.png for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_5.png for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_6.png for case RHUH-0022\n",
      "Loaded image: RHUH-0022_batch_7.png for case RHUH-0022\n",
      "Messages prepared for case RHUH-0022\n",
      "Processing inputs for case RHUH-0022\n",
      "Response generated for case RHUH-0022, length: 11842 characters\n",
      "Response saved for case RHUH-0022.\n",
      "Memory cleared for case RHUH-0022\n",
      "Found 7 image files for case RHUH-0023\n",
      "Reading clinical information for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_1.png for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_2.png for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_3.png for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_4.png for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_5.png for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_6.png for case RHUH-0023\n",
      "Loaded image: RHUH-0023_batch_7.png for case RHUH-0023\n",
      "Messages prepared for case RHUH-0023\n",
      "Processing inputs for case RHUH-0023\n",
      "Response generated for case RHUH-0023, length: 9526 characters\n",
      "Response saved for case RHUH-0023.\n",
      "Memory cleared for case RHUH-0023\n",
      "Found 5 image files for case RHUH-0024\n",
      "Reading clinical information for case RHUH-0024\n",
      "Loaded image: RHUH-0024_batch_1.png for case RHUH-0024\n",
      "Loaded image: RHUH-0024_batch_2.png for case RHUH-0024\n",
      "Loaded image: RHUH-0024_batch_3.png for case RHUH-0024\n",
      "Loaded image: RHUH-0024_batch_4.png for case RHUH-0024\n",
      "Loaded image: RHUH-0024_batch_5.png for case RHUH-0024\n",
      "Messages prepared for case RHUH-0024\n",
      "Processing inputs for case RHUH-0024\n",
      "Response generated for case RHUH-0024, length: 14392 characters\n",
      "Response saved for case RHUH-0024.\n",
      "Memory cleared for case RHUH-0024\n",
      "Found 4 image files for case RHUH-0025\n",
      "Reading clinical information for case RHUH-0025\n",
      "Loaded image: RHUH-0025_batch_1.png for case RHUH-0025\n",
      "Loaded image: RHUH-0025_batch_2.png for case RHUH-0025\n",
      "Loaded image: RHUH-0025_batch_3.png for case RHUH-0025\n",
      "Loaded image: RHUH-0025_batch_4.png for case RHUH-0025\n",
      "Messages prepared for case RHUH-0025\n",
      "Processing inputs for case RHUH-0025\n",
      "Response generated for case RHUH-0025, length: 18263 characters\n",
      "Response saved for case RHUH-0025.\n",
      "Memory cleared for case RHUH-0025\n",
      "Found 5 image files for case RHUH-0026\n",
      "Reading clinical information for case RHUH-0026\n",
      "Loaded image: RHUH-0026_batch_1.png for case RHUH-0026\n",
      "Loaded image: RHUH-0026_batch_2.png for case RHUH-0026\n",
      "Loaded image: RHUH-0026_batch_3.png for case RHUH-0026\n",
      "Loaded image: RHUH-0026_batch_4.png for case RHUH-0026\n",
      "Loaded image: RHUH-0026_batch_5.png for case RHUH-0026\n",
      "Messages prepared for case RHUH-0026\n",
      "Processing inputs for case RHUH-0026\n",
      "Response generated for case RHUH-0026, length: 2397 characters\n",
      "Response saved for case RHUH-0026.\n",
      "Memory cleared for case RHUH-0026\n",
      "Found 8 image files for case RHUH-0027\n",
      "Reading clinical information for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_1.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_2.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_3.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_4.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_5.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_6.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_7.png for case RHUH-0027\n",
      "Loaded image: RHUH-0027_batch_8.png for case RHUH-0027\n",
      "Messages prepared for case RHUH-0027\n",
      "Processing inputs for case RHUH-0027\n",
      "Response generated for case RHUH-0027, length: 11559 characters\n",
      "Response saved for case RHUH-0027.\n",
      "Memory cleared for case RHUH-0027\n",
      "Found 8 image files for case RHUH-0028\n",
      "Reading clinical information for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_1.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_2.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_3.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_4.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_5.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_6.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_7.png for case RHUH-0028\n",
      "Loaded image: RHUH-0028_batch_8.png for case RHUH-0028\n",
      "Messages prepared for case RHUH-0028\n",
      "Processing inputs for case RHUH-0028\n",
      "Response generated for case RHUH-0028, length: 2409 characters\n",
      "Response saved for case RHUH-0028.\n",
      "Memory cleared for case RHUH-0028\n",
      "Found 9 image files for case RHUH-0029\n",
      "Reading clinical information for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_1.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_2.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_3.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_4.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_5.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_6.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_7.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_8.png for case RHUH-0029\n",
      "Loaded image: RHUH-0029_batch_9.png for case RHUH-0029\n",
      "Messages prepared for case RHUH-0029\n",
      "Processing inputs for case RHUH-0029\n",
      "Response generated for case RHUH-0029, length: 19938 characters\n",
      "Response saved for case RHUH-0029.\n",
      "Memory cleared for case RHUH-0029\n",
      "Found 7 image files for case RHUH-0030\n",
      "Reading clinical information for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_1.png for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_2.png for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_3.png for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_4.png for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_5.png for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_6.png for case RHUH-0030\n",
      "Loaded image: RHUH-0030_batch_7.png for case RHUH-0030\n",
      "Messages prepared for case RHUH-0030\n",
      "Processing inputs for case RHUH-0030\n",
      "Response generated for case RHUH-0030, length: 2715 characters\n",
      "Response saved for case RHUH-0030.\n",
      "Memory cleared for case RHUH-0030\n",
      "Found 6 image files for case RHUH-0031\n",
      "Reading clinical information for case RHUH-0031\n",
      "Loaded image: RHUH-0031_batch_1.png for case RHUH-0031\n",
      "Loaded image: RHUH-0031_batch_2.png for case RHUH-0031\n",
      "Loaded image: RHUH-0031_batch_3.png for case RHUH-0031\n",
      "Loaded image: RHUH-0031_batch_4.png for case RHUH-0031\n",
      "Loaded image: RHUH-0031_batch_5.png for case RHUH-0031\n",
      "Loaded image: RHUH-0031_batch_6.png for case RHUH-0031\n",
      "Messages prepared for case RHUH-0031\n",
      "Processing inputs for case RHUH-0031\n",
      "Response generated for case RHUH-0031, length: 13040 characters\n",
      "Response saved for case RHUH-0031.\n",
      "Memory cleared for case RHUH-0031\n",
      "Found 9 image files for case RHUH-0032\n",
      "Reading clinical information for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_1.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_2.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_3.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_4.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_5.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_6.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_7.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_8.png for case RHUH-0032\n",
      "Loaded image: RHUH-0032_batch_9.png for case RHUH-0032\n",
      "Messages prepared for case RHUH-0032\n",
      "Processing inputs for case RHUH-0032\n",
      "Response generated for case RHUH-0032, length: 10860 characters\n",
      "Response saved for case RHUH-0032.\n",
      "Memory cleared for case RHUH-0032\n",
      "Found 7 image files for case RHUH-0033\n",
      "Reading clinical information for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_1.png for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_2.png for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_3.png for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_4.png for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_5.png for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_6.png for case RHUH-0033\n",
      "Loaded image: RHUH-0033_batch_7.png for case RHUH-0033\n",
      "Messages prepared for case RHUH-0033\n",
      "Processing inputs for case RHUH-0033\n",
      "Response generated for case RHUH-0033, length: 12942 characters\n",
      "Response saved for case RHUH-0033.\n",
      "Memory cleared for case RHUH-0033\n",
      "Found 7 image files for case RHUH-0034\n",
      "Reading clinical information for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_1.png for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_2.png for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_3.png for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_4.png for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_5.png for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_6.png for case RHUH-0034\n",
      "Loaded image: RHUH-0034_batch_7.png for case RHUH-0034\n",
      "Messages prepared for case RHUH-0034\n",
      "Processing inputs for case RHUH-0034\n",
      "Response generated for case RHUH-0034, length: 18086 characters\n",
      "Response saved for case RHUH-0034.\n",
      "Memory cleared for case RHUH-0034\n",
      "Found 7 image files for case RHUH-0035\n",
      "Reading clinical information for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_1.png for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_2.png for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_3.png for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_4.png for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_5.png for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_6.png for case RHUH-0035\n",
      "Loaded image: RHUH-0035_batch_7.png for case RHUH-0035\n",
      "Messages prepared for case RHUH-0035\n",
      "Processing inputs for case RHUH-0035\n",
      "Response generated for case RHUH-0035, length: 12754 characters\n",
      "Response saved for case RHUH-0035.\n",
      "Memory cleared for case RHUH-0035\n",
      "Found 8 image files for case RHUH-0036\n",
      "Reading clinical information for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_1.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_2.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_3.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_4.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_5.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_6.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_7.png for case RHUH-0036\n",
      "Loaded image: RHUH-0036_batch_8.png for case RHUH-0036\n",
      "Messages prepared for case RHUH-0036\n",
      "Processing inputs for case RHUH-0036\n",
      "Response generated for case RHUH-0036, length: 12745 characters\n",
      "Response saved for case RHUH-0036.\n",
      "Memory cleared for case RHUH-0036\n",
      "Found 6 image files for case RHUH-0037\n",
      "Reading clinical information for case RHUH-0037\n",
      "Loaded image: RHUH-0037_batch_1.png for case RHUH-0037\n",
      "Loaded image: RHUH-0037_batch_2.png for case RHUH-0037\n",
      "Loaded image: RHUH-0037_batch_3.png for case RHUH-0037\n",
      "Loaded image: RHUH-0037_batch_4.png for case RHUH-0037\n",
      "Loaded image: RHUH-0037_batch_5.png for case RHUH-0037\n",
      "Loaded image: RHUH-0037_batch_6.png for case RHUH-0037\n",
      "Messages prepared for case RHUH-0037\n",
      "Processing inputs for case RHUH-0037\n",
      "Response generated for case RHUH-0037, length: 2180 characters\n",
      "Response saved for case RHUH-0037.\n",
      "Memory cleared for case RHUH-0037\n",
      "Found 9 image files for case RHUH-0038\n",
      "Reading clinical information for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_1.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_2.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_3.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_4.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_5.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_6.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_7.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_8.png for case RHUH-0038\n",
      "Loaded image: RHUH-0038_batch_9.png for case RHUH-0038\n",
      "Messages prepared for case RHUH-0038\n",
      "Processing inputs for case RHUH-0038\n",
      "Response generated for case RHUH-0038, length: 17128 characters\n",
      "Response saved for case RHUH-0038.\n",
      "Memory cleared for case RHUH-0038\n",
      "Found 9 image files for case RHUH-0039\n",
      "Reading clinical information for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_1.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_2.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_3.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_4.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_5.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_6.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_7.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_8.png for case RHUH-0039\n",
      "Loaded image: RHUH-0039_batch_9.png for case RHUH-0039\n",
      "Messages prepared for case RHUH-0039\n",
      "Processing inputs for case RHUH-0039\n",
      "Response generated for case RHUH-0039, length: 3071 characters\n",
      "Response saved for case RHUH-0039.\n",
      "Memory cleared for case RHUH-0039\n",
      "Found 6 image files for case RHUH-0040\n",
      "Reading clinical information for case RHUH-0040\n",
      "Loaded image: RHUH-0040_batch_1.png for case RHUH-0040\n",
      "Loaded image: RHUH-0040_batch_2.png for case RHUH-0040\n",
      "Loaded image: RHUH-0040_batch_3.png for case RHUH-0040\n",
      "Loaded image: RHUH-0040_batch_4.png for case RHUH-0040\n",
      "Loaded image: RHUH-0040_batch_5.png for case RHUH-0040\n",
      "Loaded image: RHUH-0040_batch_6.png for case RHUH-0040\n",
      "Messages prepared for case RHUH-0040\n",
      "Processing inputs for case RHUH-0040\n",
      "Response generated for case RHUH-0040, length: 2928 characters\n",
      "Response saved for case RHUH-0040.\n",
      "Memory cleared for case RHUH-0040\n",
      "Failed cases logged in /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/failed_cases_2.txt\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to track failed cases\n",
    "failed_cases = []\n",
    "\n",
    "# Iterate through cases in the directory\n",
    "for case in cases_to_process:\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    if not os.path.isdir(case_dir):\n",
    "        continue  # Skip non-directory files\n",
    "\n",
    "    image_files = [f for f in os.listdir(case_dir) if f.lower().endswith('.png')]\n",
    "    print(f\"Found {len(image_files)} image files for case {case}\")\n",
    "\n",
    "    clinical_information_path = os.path.join(case_dir, 'diagnostic_prompt.txt')\n",
    "    if not os.path.exists(clinical_information_path):\n",
    "        print(f\"Missing clinical information file for case: {case}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(f\"Reading clinical information for case {case}\")    \n",
    "    clinical_information = open(clinical_information_path, 'r', encoding='utf-8').read()\n",
    "\n",
    "    system_prompt = \"\"\"Consider that you are a professional radiologist with several years of experience and you are now treating a patient. Write a fully detailed diagnosis report for this case, avoiding any potential hallucination and paying close attention to all of the batch images attached to this message.\n",
    "\n",
    "Use the following structure for the report:\n",
    "\n",
    "## Radiologist's Report\n",
    "\n",
    "### Patient Information:\n",
    "- *Age:* 65\n",
    "- *Sex:* Male\n",
    "- *Days from earliest imaging to surgery:* 1\n",
    "- *Histopathological Subtype:* Glioblastoma\n",
    "- *WHO Grade:* 4\n",
    "- *IDH Status:* Mutant\n",
    "- *Preoperative KPS:* 80\n",
    "- *Preoperative Contrast-Enhancing Tumor Volume (cm³):* 103.21\n",
    "- *Preoperative T2/FLAIR Abnormality (cm³):* 36.29\n",
    "- *Extent of Resection (EOR %):* 100.0\n",
    "- *EOR Type:* Gross Total Resection (GTR)\n",
    "- *Adjuvant Therapy:* Radiotherapy (RT) + Temozolomide (TMZ)\n",
    "- *Progression-Free Survival (PFS) Days:* 649\n",
    "- *Overall Survival (OS) Days:* 736\n",
    "\n",
    "#### Tumor Characteristics:\n",
    "\n",
    "#### Segmentation Analysis:\n",
    "\n",
    "#### Surgical Considerations:\n",
    "\n",
    "### Clinical Summary:\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "### Prognostic Considerations:\n",
    "\n",
    "### Follow-Up Plan:\n",
    "\n",
    "### Additional Notes*(if any)*:\n",
    "\n",
    "Ensure all findings from all of the images and clinical data provided. Please mention at the end of the report how many images were reviewed.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"You will be given batches of images, which are different sequences of MRI scans. \n",
    "    The images are for patients who are likely to have a brain tumor. Each image will contain up to 10 slices for 5 different sequences and the segmentation masks for the tumor at the bottom row of the image. \n",
    "    Additional clinical data about the patient is: \n",
    "    {clinical_information}\"\"\"\n",
    "\n",
    "    # Collect the last image\n",
    "    last_image = None\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(case_dir, image_file)\n",
    "        img = load_image(image_path)\n",
    "        if img is not None:\n",
    "            last_image = {\"type\": \"image\", \"image\": img}\n",
    "            print(f\"Loaded image: {image_file} for case {case}\")\n",
    "    if last_image is None:\n",
    "        print(f\"No valid images found for case: {case}\")\n",
    "        continue\n",
    "\n",
    "    # Prepare messages for Qwen2-VL\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": [last_image, {\"type\": \"text\", \"text\": user_prompt}]},\n",
    "    ]\n",
    "    print(f\"Messages prepared for case {case}\")\n",
    "\n",
    "    try:\n",
    "        # Prepare inputs for Qwen2-VL\n",
    "        print(f\"Processing inputs for case {case}\")\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "        # Generate response with gradient calculations disabled\n",
    "        with torch.no_grad():\n",
    "            inputs = processor(\n",
    "                text=[text],\n",
    "                images=image_inputs,\n",
    "                videos=video_inputs,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(model.device)\n",
    "\n",
    "            generated_ids = model.generate(**inputs, max_new_tokens=4096, temperature=0.7, top_p=0.9)\n",
    "            generated_ids_trimmed = [\n",
    "                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "            response_text = processor.batch_decode(\n",
    "                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "\n",
    "\n",
    "        print(f\"Response generated for case {case}, length: {len(response_text)} characters\")\n",
    "        # Save the response\n",
    "        response_path = os.path.join(case_dir, 'qwen-vl-2b-response.txt')\n",
    "        with open(response_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(response_text)\n",
    "        print(f\"Response saved for case {case}.\")\n",
    "        # Memory management\n",
    "        del inputs, generated_ids, response_text\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Memory cleared for case {case}\")\n",
    "        \n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(f\"CUDA out of memory error for case {case}. Skipping this case.\")\n",
    "        failed_cases.append(case)\n",
    "        continue\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user. Proceeding to the next case.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing case {case}: {e}\")\n",
    "        failed_cases.append(case)\n",
    "        continue\n",
    "\n",
    "# After processing all cases, save failed cases\n",
    "failed_cases_path = os.path.join(cases_dir, 'failed_cases_2.txt')\n",
    "with open(failed_cases_path, 'w', encoding='utf-8') as f:\n",
    "    for failed_case in failed_cases:\n",
    "        f.write(f\"{failed_case}\\n\")\n",
    "print(f\"Failed cases logged in {failed_cases_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response already exists for case RHUH-0001. Skipping.\n",
      "Response already exists for case RHUH-0004. Skipping.\n",
      "Response already exists for case RHUH-0007. Skipping.\n",
      "Response already exists for case RHUH-0009. Skipping.\n",
      "Response already exists for case RHUH-0014. Skipping.\n",
      "Response already exists for case RHUH-0015. Skipping.\n",
      "Response already exists for case RHUH-0018. Skipping.\n",
      "Response already exists for case RHUH-0020. Skipping.\n",
      "Response already exists for case RHUH-0022. Skipping.\n",
      "Response already exists for case RHUH-0023. Skipping.\n",
      "Response already exists for case RHUH-0025. Skipping.\n",
      "Response already exists for case RHUH-0026. Skipping.\n",
      "Response already exists for case RHUH-0027. Skipping.\n",
      "Response already exists for case RHUH-0035. Skipping.\n",
      "Response saved for case RHUH-0040 after retry.\n",
      "New failed cases logged in /media/RLAB-Disk01/(final)merged_images_with_labels_order_and_folders_mask_normalized/72_new_failed_cases.txt\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "failed_cases_path = os.path.join(cases_dir, 'failed_cases.txt')\n",
    "if not os.path.exists(failed_cases_path):\n",
    "    print(\"No failed cases to reprocess.\")\n",
    "    exit()\n",
    "\n",
    "with open(failed_cases_path, 'r', encoding='utf-8') as f:\n",
    "    failed_cases = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Initialize a new list for cases that fail again\n",
    "new_failed_cases = []\n",
    "\n",
    "# Set a maximum number of retries\n",
    "max_retries = 2\n",
    "\n",
    "for case in failed_cases:\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            case_dir = os.path.join(cases_dir, case)\n",
    "            response_path = os.path.join(case_dir, 'qwen-vl-72b-response.txt')\n",
    "            if os.path.exists(response_path):\n",
    "                print(f\"Response already exists for case {case}. Skipping.\")\n",
    "                break  # Skip if response already exists\n",
    "\n",
    "            # Load image and clinical information (same as before)\n",
    "            image_files = [f for f in os.listdir(case_dir) if f.lower().endswith('.png')]\n",
    "            clinical_information_path = os.path.join(case_dir, 'diagnostic_prompt.txt')\n",
    "            clinical_information = open(clinical_information_path, 'r', encoding='utf-8').read()\n",
    "\n",
    "            # Prepare messages (same as before)\n",
    "            system_prompt = \"\"\"Consider that you are a professional radiologist with several years of experience and you are now treating a patient. Write a fully detailed diagnosis report for this case, avoiding any potential hallucination and paying close attention to all of the batch images attached to this message.\n",
    "\n",
    "Use the following structure for the report:\n",
    "\n",
    "## Radiologist's Report\n",
    "\n",
    "### Patient Information:\n",
    "- *Age:* 65\n",
    "- *Sex:* Male\n",
    "- *Days from earliest imaging to surgery:* 1\n",
    "- *Histopathological Subtype:* Glioblastoma\n",
    "- *WHO Grade:* 4\n",
    "- *IDH Status:* Mutant\n",
    "- *Preoperative KPS:* 80\n",
    "- *Preoperative Contrast-Enhancing Tumor Volume (cm³):* 103.21\n",
    "- *Preoperative T2/FLAIR Abnormality (cm³):* 36.29\n",
    "- *Extent of Resection (EOR %):* 100.0\n",
    "- *EOR Type:* Gross Total Resection (GTR)\n",
    "- *Adjuvant Therapy:* Radiotherapy (RT) + Temozolomide (TMZ)\n",
    "- *Progression-Free Survival (PFS) Days:* 649\n",
    "- *Overall Survival (OS) Days:* 736\n",
    "\n",
    "#### Tumor Characteristics:\n",
    "\n",
    "#### Segmentation Analysis:\n",
    "\n",
    "#### Surgical Considerations:\n",
    "\n",
    "### Clinical Summary:\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "### Prognostic Considerations:\n",
    "\n",
    "### Follow-Up Plan:\n",
    " \n",
    "### Additional Notes*(if any)*:\n",
    "\n",
    "Ensure all findings from all of the images and clinical data provided. Please mention at the end of the report how many images were reviewed.\"\"\"\n",
    "\n",
    "            user_prompt = f\"\"\"You will be given batches of images, which are different sequences of MRI scans. \n",
    "    The images are for patients who are likely to have a brain tumor. Each image will contain up to 10 slices for 5 different sequences and the segmentation masks for the tumor at the bottom row of the image. \n",
    "    Additional clinical data about the patient is: \n",
    "    {clinical_information}\"\"\"\n",
    "\n",
    "            # Collect the last image (same as before)\n",
    "            last_image = None\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(case_dir, image_file)\n",
    "                img = load_image(image_path)\n",
    "                if img is not None:\n",
    "                    last_image = {\"type\": \"image\", \"image\": img}\n",
    "\n",
    "            if last_image is None:\n",
    "                print(f\"No valid images found for case: {case}\")\n",
    "                new_failed_cases.append(case)\n",
    "                break  # Skip this case\n",
    "\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": [last_image, {\"type\": \"text\", \"text\": user_prompt}]},\n",
    "            ]\n",
    "\n",
    "            # Prepare inputs and generate response (same as before)\n",
    "            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = processor(\n",
    "                    text=[text],\n",
    "                    images=image_inputs,\n",
    "                    videos=video_inputs,\n",
    "                    padding=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to(\"cuda\")\n",
    "\n",
    "                generated_ids = model.generate(**inputs, max_new_tokens=4096, temperature=0.7, top_p=0.9)\n",
    "                generated_ids_trimmed = [\n",
    "                    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "                ]\n",
    "                response_text = processor.batch_decode(\n",
    "                    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "                )[0]\n",
    "\n",
    "            # Save the response\n",
    "            with open(response_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(response_text)\n",
    "\n",
    "            # Memory management\n",
    "            del inputs, generated_ids, response_text\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print(f\"Response saved for case {case} after retry.\")\n",
    "            break  # Success, no need to retry\n",
    "\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"CUDA out of memory error for case {case} on retry {retry_count + 1}. Retrying...\")\n",
    "            retry_count += 1\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing case {case} on retry {retry_count + 1}: {e}\")\n",
    "            retry_count += 1\n",
    "            continue\n",
    "\n",
    "    if retry_count == max_retries:\n",
    "        print(f\"Failed to process case {case} after {max_retries} retries. Adding to new failed cases.\")\n",
    "        new_failed_cases.append(case)\n",
    "\n",
    "# Save new failed cases\n",
    "new_failed_cases_path = os.path.join(cases_dir, '72_new_failed_cases.txt')\n",
    "with open(new_failed_cases_path, 'w', encoding='utf-8') as f:\n",
    "    for failed_case in new_failed_cases:\n",
    "        f.write(f\"{failed_case}\\n\")\n",
    "print(f\"New failed cases logged in {new_failed_cases_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Qwen2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
