{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_571688/2490783814.py\", line 2, in <module>\n",
      "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1782, in __getattr__\n",
      "    value = getattr(module, name)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1781, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1793, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py\", line 21, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 40, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1781, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1793, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/generation/utils.py\", line 29, in <module>\n",
      "    from ..cache_utils import (\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/cache_utils.py\", line 1872, in <module>\n",
      "    class OffloadedStaticCache(StaticCache):\n",
      "  File \"/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/cache_utils.py\", line 1940, in OffloadedStaticCache\n",
      "    offload_device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
      "/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/transformers/cache_utils.py:1940: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  offload_device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
      "/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/elboardy/anaconda3/envs/nvidia-nemotron/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:10<00:00,  2.77it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    "                                             cache_dir='/media/elboardy/RLAB-Disk01/Large-Language-Models-Weights',\n",
    "                                )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sweet question!\n",
      "\n",
      "Let's count the \"R\"s in \"strawberry\":\n",
      "\n",
      "1. S\n",
      "2. T\n",
      "3. R\n",
      "4. A\n",
      "5. W\n",
      "6. B\n",
      "7. E\n",
      "8. R\n",
      "9. R\n",
      "10. Y\n",
      "\n",
      "There are **3 \"R\"s** in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "# Collect list of cases that do not have 'qwen-vl-72b-response.txt'\n",
    "cases_to_process = []\n",
    "for case in os.listdir(cases_dir):\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    if os.path.isdir(case_dir):\n",
    "        response_path = os.path.join(case_dir, 'nvidia-neumtron-70b-response.txt')\n",
    "        if not os.path.exists(response_path):\n",
    "            cases_to_process.append(case)\n",
    "print(f\"Found {len(cases_to_process)} cases to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing cases...--->\")\n",
    "print(cases_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to track failed cases\n",
    "failed_cases = []\n",
    "\n",
    "# Iterate through cases in the directory\n",
    "for case in cases_to_process:\n",
    "    case_dir = os.path.join(cases_dir, case)\n",
    "    if not os.path.isdir(case_dir):\n",
    "        continue  # Skip non-directory files\n",
    "\n",
    "    image_files = [f for f in os.listdir(case_dir) if f.lower().endswith('.png')]\n",
    "    print(f\"Found {len(image_files)} image files for case {case}\")\n",
    "\n",
    "    clinical_information_path = os.path.join(case_dir, 'diagnostic_prompt.txt')\n",
    "    if not os.path.exists(clinical_information_path):\n",
    "        print(f\"Missing clinical information file for case: {case}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(f\"Reading clinical information for case {case}\")    \n",
    "    clinical_information = open(clinical_information_path, 'r', encoding='utf-8').read()\n",
    "\n",
    "    system_prompt = \"\"\"Consider that you are a professional radiologist with several years of experience and you are now treating a patient. Write a fully detailed diagnosis report for this case, avoiding any potential hallucination and paying close attention to all of the batch images attached to this message.\n",
    "\n",
    "Use the following structure for the report:\n",
    "\n",
    "## Radiologist's Report\n",
    "\n",
    "### Patient Information:\n",
    "- *Age:* 65\n",
    "- *Sex:* Male\n",
    "- *Days from earliest imaging to surgery:* 1\n",
    "- *Histopathological Subtype:* Glioblastoma\n",
    "- *WHO Grade:* 4\n",
    "- *IDH Status:* Mutant\n",
    "- *Preoperative KPS:* 80\n",
    "- *Preoperative Contrast-Enhancing Tumor Volume (cm³):* 103.21\n",
    "- *Preoperative T2/FLAIR Abnormality (cm³):* 36.29\n",
    "- *Extent of Resection (EOR %):* 100.0\n",
    "- *EOR Type:* Gross Total Resection (GTR)\n",
    "- *Adjuvant Therapy:* Radiotherapy (RT) + Temozolomide (TMZ)\n",
    "- *Progression-Free Survival (PFS) Days:* 649\n",
    "- *Overall Survival (OS) Days:* 736\n",
    "\n",
    "#### Tumor Characteristics:\n",
    "\n",
    "#### Segmentation Analysis:\n",
    "\n",
    "#### Surgical Considerations:\n",
    "\n",
    "### Clinical Summary:\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "### Prognostic Considerations:\n",
    "\n",
    "### Follow-Up Plan:\n",
    "\n",
    "### Additional Notes*(if any)*:\n",
    "\n",
    "Ensure all findings from all of the images and clinical data provided. Please mention at the end of the report how many images were reviewed.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"You will be given batches of images, which are different sequences of MRI scans. \n",
    "    The images are for patients who are likely to have a brain tumor. Each image will contain up to 10 slices for 5 different sequences and the segmentation masks for the tumor at the bottom row of the image. \n",
    "    Additional clinical data about the patient is: \n",
    "    {clinical_information}\"\"\"\n",
    "\n",
    "    # Collect the last image\n",
    "    last_image = None\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(case_dir, image_file)\n",
    "        img = load_image(image_path)\n",
    "        if img is not None:\n",
    "            last_image = {\"type\": \"image\", \"image\": img}\n",
    "            print(f\"Loaded image: {image_file} for case {case}\")\n",
    "    if last_image is None:\n",
    "        print(f\"No valid images found for case: {case}\")\n",
    "        continue\n",
    "\n",
    "    # Prepare messages for Qwen2-VL\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": [last_image, {\"type\": \"text\", \"text\": user_prompt}]},\n",
    "    ]\n",
    "    print(f\"Messages prepared for case {case}\")\n",
    "\n",
    "    try:\n",
    "        # Prepare inputs for Qwen2-VL\n",
    "        print(f\"Processing inputs for case {case}\")\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "        # Generate response with gradient calculations disabled\n",
    "        with torch.no_grad():\n",
    "            inputs = processor(\n",
    "                text=[text],\n",
    "                images=image_inputs,\n",
    "                videos=video_inputs,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(model.device)\n",
    "\n",
    "            generated_ids = model.generate(**inputs, max_new_tokens=4096, temperature=0.7, top_p=0.9)\n",
    "            generated_ids_trimmed = [\n",
    "                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "            response_text = processor.batch_decode(\n",
    "                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "\n",
    "\n",
    "        print(f\"Response generated for case {case}, length: {len(response_text)} characters\")\n",
    "        # Save the response\n",
    "        response_path = os.path.join(case_dir, 'qwen-vl-72b-response.txt')\n",
    "        with open(response_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(response_text)\n",
    "        print(f\"Response saved for case {case}.\")\n",
    "        # Memory management\n",
    "        del inputs, generated_ids, response_text\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Memory cleared for case {case}\")\n",
    "        \n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(f\"CUDA out of memory error for case {case}. Skipping this case.\")\n",
    "        failed_cases.append(case)\n",
    "        continue\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user. Proceeding to the next case.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing case {case}: {e}\")\n",
    "        failed_cases.append(case)\n",
    "        continue\n",
    "\n",
    "# After processing all cases, save failed cases\n",
    "failed_cases_path = os.path.join(cases_dir, 'failed_cases_72.txt')\n",
    "with open(failed_cases_path, 'w', encoding='utf-8') as f:\n",
    "    for failed_case in failed_cases:\n",
    "        f.write(f\"{failed_case}\\n\")\n",
    "print(f\"Failed cases logged in {failed_cases_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia-nemotron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
